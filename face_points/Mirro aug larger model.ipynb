{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# sess_cpu = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(device_count={'GPU': 0}))\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 165\n",
    "CROP_SIZE = 150\n",
    "DS_SIZE = 6000\n",
    "EPS = 1e-8\n",
    "BATCH_SIZE = 30\n",
    "MAX_SHIFT = IMG_SIZE - CROP_SIZE\n",
    "ROTATE_MAX = 15\n",
    "half = MAX_SHIFT // 2\n",
    "mirror_map = [3, 2, 1, 0, 9, 8, 7, 6, 5, 4, 10, 13, 12, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers import Dense, Activation, ReLU, Conv2D, MaxPool2D, BatchNormalization, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize(filename, Y, num):\n",
    "    image = imread(filename)\n",
    "    hei = image.shape[0]\n",
    "    wid = image.shape[1]\n",
    "    Y[i,::2] = (Y[i,::2] * IMG_SIZE) / wid\n",
    "    Y[i,1::2] = (Y[i,1::2] * IMG_SIZE) / hei\n",
    "    image = resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack((image, image, image))\n",
    "        image = np.transpose(image, axes=(1,2, 0))\n",
    "#     print(image.shape)\n",
    "    for channel in range(3):\n",
    "        image[:,:,channel] = (image[:,:,channel] - np.mean(image[:,:,channel])) / (np.std(image[:,:,channel]) + EPS)\n",
    "#     print(image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gt():\n",
    "#     csv_file = csv.DictReader(open('public_tests/00_test_img_input/train/gt.csv'))\n",
    "#     lines = [line for line in csv_file]\n",
    "    lines = pd.read_csv('public_tests/00_test_img_input/train/gt.csv')\n",
    "    lines.drop('filename', axis=1, inplace=True)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = read_gt()[:100]\n",
    "# print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(200, 300):\n",
    "#     print(i)\n",
    "#     X[i] = \n",
    "# img = load_and_resize('public_tests/00_test_img_input/train/images/{:05}.jpg'.format(20))\n",
    "# print(img.shape)\n",
    "# print(img[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loaded\n",
      "500 loaded\n",
      "1000 loaded\n",
      "1500 loaded\n",
      "2000 loaded\n",
      "2500 loaded\n",
      "3000 loaded\n",
      "3500 loaded\n",
      "4000 loaded\n",
      "4500 loaded\n",
      "5000 loaded\n",
      "5500 loaded\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((DS_SIZE, IMG_SIZE, IMG_SIZE, 3))\n",
    "Y = read_gt()[:DS_SIZE].values.astype(float)\n",
    "for i in range(DS_SIZE):\n",
    "#     print(Y[i])\n",
    "    X[i] = load_and_resize('public_tests/00_test_img_input/train/images/{:05}.jpg'.format(i), Y, i)\n",
    "#     print(Y[i])\n",
    "    if i % 500 == 0:\n",
    "        print('{} loaded'.format(i))\n",
    "#     print('public_tests/00_test_img_input/train/images/{:05}.jpg'.format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006208333333333333\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(Y < 20) / 168000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(80, kernel_size=(3,3), input_shape=(CROP_SIZE, CROP_SIZE, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(160, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(320, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(80, activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(28))\n",
    "# model = keras.models.load_model('dropout_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.transform import SimilarityTransform\n",
    "from skimage.transform import warp\n",
    "\n",
    "def rotate_transform_matrix(transform):\n",
    "    \"\"\"Rotate matrix so it can be applied to row:col coordinates.\"\"\"\n",
    "    matrix = transform.params[(1, 0, 2), :][:, (1, 0, 2)]\n",
    "    return type(transform)(matrix)\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, images, points, batch_size=BATCH_SIZE,\n",
    "                 shuffle=True, seed=None):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.points = points\n",
    "        self.images = images\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        if seed:\n",
    "            random.seed(20)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.images) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        image_batch = [self.images[k] for k in indexes]\n",
    "        points_batch = [self.points[k] for k in indexes]\n",
    "        \n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(image_batch, points_batch)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.images))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, image_batch, points_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, CROP_SIZE, CROP_SIZE, 3))\n",
    "        y = np.empty((self.batch_size,*points_batch[0].shape))\n",
    "\n",
    "        # Generate data\n",
    "        for i in range(self.batch_size):\n",
    "            # Store sample\n",
    "            mirror = bool(random.getrandbits(1))\n",
    "            angle = random.random() * 2 * ROTATE_MAX - ROTATE_MAX\n",
    "            center = np.array((IMG_SIZE, IMG_SIZE)) / 2. - 0.5\n",
    "            tform1 = SimilarityTransform(translation=center)\n",
    "            tform2 = SimilarityTransform(rotation=np.deg2rad(angle))\n",
    "            tform3 = SimilarityTransform(translation=-center)\n",
    "            tform = tform3 + tform2 + tform1\n",
    "            tform.params[2] = (0, 0, 1)\n",
    "            rotated_img = warp(image_batch[i], rotate_transform_matrix(tform).inverse)\n",
    "            if mirror:\n",
    "                rotated_img = np.fliplr(rotated_img)\n",
    "#             rotated_img = image_batch[i]\n",
    "            \n",
    "            dx = half # random.randint(0, MAX_SHIFT)\n",
    "            dy = half # random.randint(0, MAX_SHIFT)\n",
    "#             print(f\"{dx} {dy}\")\n",
    "            X[i,] = rotated_img[dx:dx+CROP_SIZE,dy:dy+CROP_SIZE,:]\n",
    "            for p_num in range(14):\n",
    "                rotated_point = tform([points_batch[i][p_num*2+1], points_batch[i][p_num*2]])\n",
    "#                 rotated_point = [[points_batch[i][p_num*2+1], points_batch[i][p_num*2]]]\n",
    "                if mirror:\n",
    "                    y[i,mirror_map[p_num]*2+1] = (rotated_point[0][0]-dy) / CROP_SIZE - 0.5\n",
    "                    y[i,mirror_map[p_num]*2] = (CROP_SIZE - (rotated_point[0][1]-dx)) / CROP_SIZE - 0.5\n",
    "                else:\n",
    "                    y[i,p_num*2+1] = (rotated_point[0][0]-dy) / CROP_SIZE - 0.5\n",
    "                    y[i,p_num*2] = (rotated_point[0][1]-dx) / CROP_SIZE - 0.5\n",
    "                \n",
    "\n",
    "            # Store class\n",
    "#             y[i,::2] = points_batch[i][::2] - dx\n",
    "#             y[i,1::2] = points_batch[i][1::2] - dy\n",
    "            \n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator()\n",
    "# train_datagen.fit(x_train)\n",
    "# train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "# step = x_train.shape[0] // BATCH_SIZE\n",
    "\n",
    "train_generator = DataGenerator(x_train, y_train, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 80)      2240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 148, 148, 80)      320       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 148, 148, 80)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 160)       115360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 72, 72, 160)       640       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 72, 72, 160)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 160)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 34, 34, 320)       461120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 34, 34, 320)       1280      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 34, 34, 320)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 320)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 92480)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                7398480   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 28)                2268      \n",
      "=================================================================\n",
      "Total params: 7,981,708\n",
      "Trainable params: 7,980,588\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 66s 411ms/step - loss: 7.8750 - accuracy: 0.7667 - val_loss: 0.0405 - val_accuracy: 0.8175\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0362 - accuracy: 0.7754 - val_loss: 0.0321 - val_accuracy: 0.8175\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0287 - accuracy: 0.7835 - val_loss: 0.0253 - val_accuracy: 0.8175\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 63s 391ms/step - loss: 0.0228 - accuracy: 0.7806 - val_loss: 0.0200 - val_accuracy: 0.8175\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0181 - accuracy: 0.7804 - val_loss: 0.0158 - val_accuracy: 0.8175\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0144 - accuracy: 0.7908 - val_loss: 0.0126 - val_accuracy: 0.8175\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 63s 393ms/step - loss: 0.0117 - accuracy: 0.7796 - val_loss: 0.0101 - val_accuracy: 0.8175\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 63s 393ms/step - loss: 0.0095 - accuracy: 0.7881 - val_loss: 0.0083 - val_accuracy: 0.8175\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0080 - accuracy: 0.7871 - val_loss: 0.0069 - val_accuracy: 0.8175\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 63s 391ms/step - loss: 0.0068 - accuracy: 0.7908 - val_loss: 0.0059 - val_accuracy: 0.8175\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 63s 391ms/step - loss: 0.0061 - accuracy: 0.7790 - val_loss: 0.0052 - val_accuracy: 0.8175\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0056 - accuracy: 0.7925 - val_loss: 0.0048 - val_accuracy: 0.8175\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0052 - accuracy: 0.7862 - val_loss: 0.0045 - val_accuracy: 0.8175\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0050 - accuracy: 0.7933 - val_loss: 0.0043 - val_accuracy: 0.8175\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0047 - accuracy: 0.7900 - val_loss: 0.0041 - val_accuracy: 0.8175\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0048 - accuracy: 0.7919 - val_loss: 0.0041 - val_accuracy: 0.8175\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.0046 - accuracy: 0.7952 - val_loss: 0.0040 - val_accuracy: 0.8175\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 63s 393ms/step - loss: 0.0047 - accuracy: 0.7852 - val_loss: 0.0040 - val_accuracy: 0.8175\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 72s 449ms/step - loss: 0.0046 - accuracy: 0.7796 - val_loss: 0.0039 - val_accuracy: 0.8175\n",
      "Epoch 20/50\n",
      "133/160 [=======================>......] - ETA: 10s - loss: 0.0045 - accuracy: 0.7905"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "#     steps_per_epoch=step, \n",
    "    epochs=50,\n",
    "    validation_data=(x_test[:, half:half+CROP_SIZE, half:half+CROP_SIZE, :], (y_test - half) / CROP_SIZE - 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 7.7407e-04 - accuracy: 0.8244 - val_loss: 0.0011 - val_accuracy: 0.8608\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 7.4610e-04 - accuracy: 0.8210 - val_loss: 0.0011 - val_accuracy: 0.8617\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 7.6196e-04 - accuracy: 0.8179 - val_loss: 0.0011 - val_accuracy: 0.8583\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 7.2860e-04 - accuracy: 0.8273 - val_loss: 0.0011 - val_accuracy: 0.8608\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 7.1773e-04 - accuracy: 0.8277 - val_loss: 0.0011 - val_accuracy: 0.8575\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 7.0593e-04 - accuracy: 0.8273 - val_loss: 0.0011 - val_accuracy: 0.8625\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 7.1155e-04 - accuracy: 0.8225 - val_loss: 0.0011 - val_accuracy: 0.8608\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 7.1418e-04 - accuracy: 0.8246 - val_loss: 0.0012 - val_accuracy: 0.8558\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 7.4280e-04 - accuracy: 0.8181 - val_loss: 0.0011 - val_accuracy: 0.8517\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 7.0016e-04 - accuracy: 0.8360 - val_loss: 0.0011 - val_accuracy: 0.8600\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.8146e-04 - accuracy: 0.8223 - val_loss: 0.0011 - val_accuracy: 0.8550\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.7612e-04 - accuracy: 0.8283 - val_loss: 0.0011 - val_accuracy: 0.8558\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 6.5892e-04 - accuracy: 0.8338 - val_loss: 0.0011 - val_accuracy: 0.8517\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 6.6663e-04 - accuracy: 0.8250 - val_loss: 0.0011 - val_accuracy: 0.8583\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 6.8137e-04 - accuracy: 0.8233 - val_loss: 0.0011 - val_accuracy: 0.8475\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 6.6381e-04 - accuracy: 0.8258 - val_loss: 0.0010 - val_accuracy: 0.8633\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 6.6406e-04 - accuracy: 0.8260 - val_loss: 0.0011 - val_accuracy: 0.8500\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 6.3862e-04 - accuracy: 0.8294 - val_loss: 0.0010 - val_accuracy: 0.8508\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 6.4149e-04 - accuracy: 0.8313 - val_loss: 0.0010 - val_accuracy: 0.8475\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.4312e-04 - accuracy: 0.8267 - val_loss: 0.0010 - val_accuracy: 0.8575\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.8057e-04 - accuracy: 0.8360 - val_loss: 0.0010 - val_accuracy: 0.8550\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 36s 446ms/step - loss: 6.5410e-04 - accuracy: 0.8294 - val_loss: 0.0010 - val_accuracy: 0.8508\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.3907e-04 - accuracy: 0.8304 - val_loss: 0.0011 - val_accuracy: 0.8550\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.4784e-04 - accuracy: 0.8258 - val_loss: 0.0011 - val_accuracy: 0.8583\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.2581e-04 - accuracy: 0.8310 - val_loss: 0.0011 - val_accuracy: 0.8592\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 36s 450ms/step - loss: 6.2030e-04 - accuracy: 0.8350 - val_loss: 0.0010 - val_accuracy: 0.8625\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 36s 451ms/step - loss: 6.2294e-04 - accuracy: 0.8333 - val_loss: 0.0010 - val_accuracy: 0.8517\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 37s 457ms/step - loss: 5.9302e-04 - accuracy: 0.8304 - val_loss: 0.0011 - val_accuracy: 0.8533\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 36s 450ms/step - loss: 6.3556e-04 - accuracy: 0.8296 - val_loss: 9.8034e-04 - val_accuracy: 0.8500\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 36s 451ms/step - loss: 6.2408e-04 - accuracy: 0.8300 - val_loss: 9.7621e-04 - val_accuracy: 0.8483\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 6.0981e-04 - accuracy: 0.8277 - val_loss: 9.9646e-04 - val_accuracy: 0.8608\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.2283e-04 - accuracy: 0.8350 - val_loss: 0.0011 - val_accuracy: 0.8558\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 6.2093e-04 - accuracy: 0.8242 - val_loss: 0.0011 - val_accuracy: 0.8558\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.3780e-04 - accuracy: 0.8250 - val_loss: 0.0011 - val_accuracy: 0.8533\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 36s 445ms/step - loss: 6.0117e-04 - accuracy: 0.8317 - val_loss: 0.0010 - val_accuracy: 0.8567\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 5.9805e-04 - accuracy: 0.8342 - val_loss: 0.0010 - val_accuracy: 0.8642\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 5.9319e-04 - accuracy: 0.8327 - val_loss: 0.0010 - val_accuracy: 0.8542\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 5.8395e-04 - accuracy: 0.8342 - val_loss: 0.0010 - val_accuracy: 0.8558\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 5.7285e-04 - accuracy: 0.8342 - val_loss: 9.8960e-04 - val_accuracy: 0.8517\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 5.7188e-04 - accuracy: 0.8352 - val_loss: 0.0011 - val_accuracy: 0.8600\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 5.7082e-04 - accuracy: 0.8310 - val_loss: 0.0011 - val_accuracy: 0.8567\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 5.6804e-04 - accuracy: 0.8423 - val_loss: 0.0011 - val_accuracy: 0.8600\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 5.8252e-04 - accuracy: 0.8298 - val_loss: 0.0010 - val_accuracy: 0.8525\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 5.7014e-04 - accuracy: 0.8431 - val_loss: 0.0010 - val_accuracy: 0.8575\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 5.5843e-04 - accuracy: 0.8300 - val_loss: 0.0010 - val_accuracy: 0.8567\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 36s 444ms/step - loss: 5.4343e-04 - accuracy: 0.8329 - val_loss: 9.8241e-04 - val_accuracy: 0.8633\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 5.8416e-04 - accuracy: 0.8348 - val_loss: 0.0011 - val_accuracy: 0.8542\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 5.7509e-04 - accuracy: 0.8356 - val_loss: 0.0011 - val_accuracy: 0.8617\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 5.6651e-04 - accuracy: 0.8400 - val_loss: 0.0011 - val_accuracy: 0.8550\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 36s 450ms/step - loss: 5.5637e-04 - accuracy: 0.8415 - val_loss: 0.0010 - val_accuracy: 0.8517\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "#     steps_per_epoch=step, \n",
    "    epochs=50,\n",
    "    validation_data=(x_test[:, half:half+CROP_SIZE, half:half+CROP_SIZE, :], (y_test - half) / CROP_SIZE - 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('dropout_mirrored_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test[:, half:half+CROP_SIZE, half:half+CROP_SIZE, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 28)\n",
      "10.470492994338189\n"
     ]
    }
   ],
   "source": [
    "def compute_metric(pred, test):\n",
    "    res = 0.0\n",
    "    hei = pred.shape[0]\n",
    "    print(pred.shape)\n",
    "    for i in range(hei):\n",
    "        diff = (pred[i] - test[i])\n",
    "#         diff[::2] /= n_cols\n",
    "#         diff[1::2] /= n_rows\n",
    "#         diff *= 100\n",
    "#         print((diff ** 2).mean())\n",
    "#         diff = diff / CROP_SIZE * 100\n",
    "        diff *= 100\n",
    "        res += (diff ** 2).mean()\n",
    "    return res / hei\n",
    "\n",
    "print(compute_metric(y_pred, (y_test - half) / CROP_SIZE - 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26 24  5 28  4 25 22 12 19 23 14 23  9 22  5 18 11 18 16 15  5  3 21  3\n",
      "  9  9  3  7]\n",
      "[2 7 2 7 1 5 0 3 2 7 1 8 3 7 6 6 5 5 6 4 1 4 4 6 3 6 5 4]\n",
      "[1 6 2 6 4 3 6 2 3 6 2 6 3 4 0 4 4 3 5 2 2 8 4 4 3 2 7 5]\n",
      "[ 2  6  3  2  4  5  6 10  5  4  4  4  6  4  7  6  7  6  8  6  3  3  4  0\n",
      "  4  3  5  2]\n",
      "[5 5 5 5 4 2 1 3 2 3 3 2 5 3 1 2 4 1 5 0 7 0 3 1 5 0 5 1]\n",
      "[5 2 6 2 7 4 5 8 5 1 4 2 3 1 6 4 7 4 5 5 6 5 5 0 5 3 8 3]\n",
      "[2 4 2 6 1 7 5 5 2 5 3 4 4 6 2 4 2 4 3 4 1 2 3 4 2 3 1 3]\n",
      "[6 4 3 9 4 9 3 6 8 4 6 3 5 5 2 5 2 5 2 6 0 2 2 0 0 0 1 2]\n",
      "[4 3 2 2 4 2 6 4 5 6 6 6 7 8 3 7 5 6 6 5 5 5 8 6 5 4 4 4]\n",
      "[4 5 4 9 8 7 6 8 5 4 8 4 5 4 3 4 4 5 4 5 1 7 6 8 3 6 0 7]\n",
      "[5 7 8 5 5 6 6 9 8 5 7 3 8 5 5 6 5 5 5 5 7 3 5 2 7 2 5 3]\n",
      "[3 3 6 0 6 0 1 4 7 4 5 5 5 5 2 3 4 5 4 4 1 5 0 3 4 4 4 2]\n",
      "[4 7 1 5 1 5 1 5 3 5 3 4 6 2 3 4 6 4 6 3 0 4 2 6 3 4 2 3]\n",
      "[ 7  5  5  0  5  2 13  2 10  1  9  0 11  1 11  3 15  4 17  5  3  4 11  4\n",
      "  9  1 13  1]\n",
      "[ 2 20  0 19  1  9 11  3  0 18  0 17  0 12  4  6  6  4  6  1  5  9  0  3\n",
      "  2  0  2 11]\n",
      "[4 8 0 7 2 6 3 6 5 5 4 4 4 3 4 1 6 3 6 4 4 5 6 5 4 4 5 3]\n",
      "[1 5 5 8 0 5 0 3 3 8 2 7 0 6 8 5 8 5 4 4 0 9 2 6 1 4 6 3]\n",
      "[6 0 6 0 4 4 5 2 5 2 7 4 7 3 5 3 5 5 7 5 4 0 4 1 3 1 5 0]\n",
      "[3 7 3 2 2 0 6 4 5 5 6 4 4 7 4 5 4 2 5 4 4 0 7 2 7 0 8 1]\n",
      "[6 5 6 4 4 4 5 4 7 7 4 5 4 5 6 3 4 3 4 2 7 4 1 4 4 2 6 5]\n",
      "[1 4 4 4 4 4 5 5 0 1 8 2 9 0 4 2 4 3 5 4 9 5 9 0 7 1 2 0]\n",
      "[ 9  1  2  2  2  1  4  0 12  0  9  1  4  1 10  0  9  0  3  0  3  6 12  1\n",
      "  5  2  7  3]\n",
      "[5 1 5 2 3 5 2 7 1 2 3 4 3 2 4 3 5 6 4 4 1 7 1 3 1 4 1 9]\n",
      "[8 4 8 6 5 6 7 5 6 3 7 5 7 4 5 4 6 6 9 4 2 4 4 5 4 4 5 3]\n",
      "[9 5 2 7 3 7 3 8 2 7 0 5 4 7 5 8 1 5 2 4 4 3 4 8 6 7 3 7]\n",
      "[5 6 1 3 7 5 5 6 7 6 6 6 5 6 3 7 2 6 7 6 7 3 6 5 6 3 4 3]\n",
      "[ 1  2  9  2  4  1  3  3  6  0  4  1  7  2  4  3  2  2  5  3  7  2  8  0\n",
      " 10  0 12  2]\n",
      "[1 1 7 4 6 3 6 9 5 6 3 4 4 6 6 5 5 6 6 5 2 2 8 6 4 3 0 5]\n",
      "[ 3  5 11  6  0  7  4  5  4  6  4  5  3  6  3  6  2  5  9  3  4  2  1  3\n",
      "  4  4  5  1]\n",
      "[ 2 14  1 11  5  0  8  2  5 21  0 17  3 15  6  7  7  3  6  1  5  7  1 11\n",
      "  0  5  0  2]\n",
      "[ 8  4  6  3  7  3  1  2  9  5 10  3  7  4  5  4  5  4  4  4  4  3  7  3\n",
      "  8  1  4  3]\n",
      "[1 8 2 6 2 6 6 5 6 7 5 7 3 5 4 4 4 4 1 3 6 7 5 7 5 8 6 4]\n",
      "[6 7 1 8 5 2 1 6 9 5 9 6 3 4 5 5 7 6 3 6 7 6 4 2 3 3 5 3]\n",
      "[ 4  1  0  6  8  7  4  8  8  3  6  3  7  4  4  5  5  5  4  4  2 11  1  0\n",
      "  1  3  0  3]\n",
      "[6 4 7 6 7 6 7 1 6 5 6 4 7 4 5 5 4 3 6 2 1 4 4 0 0 0 0 1]\n",
      "[5 8 7 8 9 9 4 9 6 4 4 4 6 4 7 4 7 6 5 7 4 2 0 3 2 4 6 4]\n",
      "[10  6  6  4  5  5  8 11  7  0  7  0  6  2  3  4  3  2  1  4  7 11  2  4\n",
      "  4  2  4  0]\n",
      "[6 3 7 5 4 6 7 5 7 4 6 3 7 5 5 5 7 4 6 5 4 4 6 4 5 2 6 4]\n",
      "[2 1 6 3 3 7 3 7 4 1 2 2 4 0 7 5 6 8 6 9 2 5 3 2 1 3 3 4]\n",
      "[ 8  3  5  2  6  0 10  0  7  3  4  4  6  4  9  3  7  3  8  3  6  3  9  1\n",
      "  6  0  3  0]\n",
      "[10  2  6  4  7  3  1  1  6  4  5  4  6  4  7  3  6  2  5  0  8  4  3  6\n",
      "  2  5  1  8]\n",
      "[ 6  2  6  4  6  3  4  0  7  0  6  0  6  0  4  2  5  1  3  1  8  0  2  5\n",
      "  3 12  6  3]\n",
      "[1 9 3 5 6 4 7 7 5 6 6 6 4 5 1 5 4 4 2 3 6 2 8 5 7 4 4 4]\n",
      "[10  3  8  4  6  7  5  7  8  3  5  5  7  4  8  4  5  7  5  5  3  2  4  5\n",
      "  3  3  5  6]\n",
      "[5 8 2 6 8 3 5 1 4 8 4 6 5 7 5 5 4 3 5 4 8 7 6 7 7 5 6 4]\n",
      "[9 2 7 1 9 4 2 7 6 2 6 2 5 4 3 7 3 8 3 9 1 9 2 3 0 5 1 8]\n",
      "[2 8 3 4 4 9 6 7 3 2 0 4 1 4 3 1 4 3 4 3 3 2 2 2 2 1 2 2]\n",
      "[ 7  2  5  3  4  7  0  4  2  6  4  6  2  7  2  6  1  8  2  8  2 12  1  6\n",
      "  1  8  2  9]\n",
      "[6 8 7 4 5 2 5 3 7 6 5 5 5 6 4 4 4 2 4 2 5 5 6 4 5 3 5 2]\n",
      "[ 1  5  4  4  8  3 10  3  4  5  5  6  5  5  5  4  5  4  7  4  7  0 15  6\n",
      "  9  2  7  5]\n"
     ]
    }
   ],
   "source": [
    "for line in range(50):\n",
    "#     print(y_pred[line])\n",
    "#     print(y_test[line])\n",
    "    print((np.abs(y_pred[line] - y_test[line])).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
