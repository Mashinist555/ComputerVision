{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100\n",
    "DS_SIZE = 6000\n",
    "EPS = 1e-8\n",
    "BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers import Dense, Activation, ReLU, Conv2D, MaxPool2D, BatchNormalization, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize(filename, Y, num):\n",
    "    image = imread(filename)\n",
    "    hei = image.shape[0]\n",
    "    wid = image.shape[1]\n",
    "    Y[i,::2] = (Y[i,::2] * 100) / wid\n",
    "    Y[i,1::2] = (Y[i,1::2] * 100) / hei\n",
    "    image = resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack((image, image, image))\n",
    "        image = np.transpose(image, axes=(1,2, 0))\n",
    "#     print(image.shape)\n",
    "    for channel in range(3):\n",
    "        image[:,:,channel] = (image[:,:,channel] - np.mean(image[:,:,channel])) / (np.std(image[:,:,channel]) + EPS)\n",
    "#     print(image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gt():\n",
    "#     csv_file = csv.DictReader(open('public_tests/00_test_img_input/train/gt.csv'))\n",
    "#     lines = [line for line in csv_file]\n",
    "    lines = pd.read_csv('public_tests/00_test_img_input/train/gt.csv')\n",
    "    lines.drop('filename', axis=1, inplace=True)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = read_gt()[:100]\n",
    "# print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(200, 300):\n",
    "#     print(i)\n",
    "#     X[i] = \n",
    "# img = load_and_resize('public_tests/00_test_img_input/train/images/{:05}.jpg'.format(20))\n",
    "# print(img.shape)\n",
    "# print(img[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loaded\n",
      "100 loaded\n",
      "200 loaded\n",
      "300 loaded\n",
      "400 loaded\n",
      "500 loaded\n",
      "600 loaded\n",
      "700 loaded\n",
      "800 loaded\n",
      "900 loaded\n",
      "1000 loaded\n",
      "1100 loaded\n",
      "1200 loaded\n",
      "1300 loaded\n",
      "1400 loaded\n",
      "1500 loaded\n",
      "1600 loaded\n",
      "1700 loaded\n",
      "1800 loaded\n",
      "1900 loaded\n",
      "2000 loaded\n",
      "2100 loaded\n",
      "2200 loaded\n",
      "2300 loaded\n",
      "2400 loaded\n",
      "2500 loaded\n",
      "2600 loaded\n",
      "2700 loaded\n",
      "2800 loaded\n",
      "2900 loaded\n",
      "3000 loaded\n",
      "3100 loaded\n",
      "3200 loaded\n",
      "3300 loaded\n",
      "3400 loaded\n",
      "3500 loaded\n",
      "3600 loaded\n",
      "3700 loaded\n",
      "3800 loaded\n",
      "3900 loaded\n",
      "4000 loaded\n",
      "4100 loaded\n",
      "4200 loaded\n",
      "4300 loaded\n",
      "4400 loaded\n",
      "4500 loaded\n",
      "4600 loaded\n",
      "4700 loaded\n",
      "4800 loaded\n",
      "4900 loaded\n",
      "5000 loaded\n",
      "5100 loaded\n",
      "5200 loaded\n",
      "5300 loaded\n",
      "5400 loaded\n",
      "5500 loaded\n",
      "5600 loaded\n",
      "5700 loaded\n",
      "5800 loaded\n",
      "5900 loaded\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((DS_SIZE, IMG_SIZE, IMG_SIZE, 3))\n",
    "Y = read_gt()[:DS_SIZE].values.astype(float)\n",
    "for i in range(DS_SIZE):\n",
    "#     print(Y[i])\n",
    "    X[i] = load_and_resize('public_tests/00_test_img_input/train/images/{:05}.jpg'.format(i), Y, i)\n",
    "#     print(Y[i])\n",
    "    if i % 100 == 0:\n",
    "        print('{} loaded'.format(i))\n",
    "#     print('public_tests/00_test_img_input/train/images/{:05}.jpg'.format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.46564885 19.46564885 48.47328244 ... 68.70229008 64.1221374\n",
      "  68.32061069]\n",
      " [22.34042553 21.27659574 38.29787234 ... 70.21276596 63.82978723\n",
      "  69.14893617]\n",
      " [13.85542169 69.87951807 23.4939759  ... 60.24096386 72.89156627\n",
      "  48.79518072]\n",
      " ...\n",
      " [13.46153846 21.15384615 26.28205128 ... 73.07692308 60.25641026\n",
      "  71.15384615]\n",
      " [15.68627451 25.49019608 33.33333333 ... 68.62745098 66.66666667\n",
      "  66.66666667]\n",
      " [19.14893617 17.0212766  36.17021277 ... 70.21276596 68.08510638\n",
      "  68.08510638]]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(64, kernel_size=(3,3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "train_datagen.fit(x_train)\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "step = x_train.shape[0] // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(layer):\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.square())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 98, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 98, 98, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 47, 47, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 47, 47, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 21, 21, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 21, 21, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1638464   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28)                1820      \n",
      "=================================================================\n",
      "Total params: 2,012,892\n",
      "Trainable params: 2,011,996\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "160/160 [==============================] - 24s 147ms/step - loss: 119.6992 - accuracy: 0.6402 - val_loss: 35.8962 - val_accuracy: 0.6100\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 23s 146ms/step - loss: 22.9114 - accuracy: 0.7554 - val_loss: 42.8321 - val_accuracy: 0.6075\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 23s 146ms/step - loss: 19.4324 - accuracy: 0.7571 - val_loss: 60.3941 - val_accuracy: 0.7817\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 23s 145ms/step - loss: 17.4547 - accuracy: 0.7552 - val_loss: 20.8389 - val_accuracy: 0.8158\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 23s 146ms/step - loss: 14.3456 - accuracy: 0.8004 - val_loss: 23.1839 - val_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 23s 146ms/step - loss: 13.5558 - accuracy: 0.8000 - val_loss: 22.1747 - val_accuracy: 0.8375\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 23s 145ms/step - loss: 12.6988 - accuracy: 0.8206 - val_loss: 31.2204 - val_accuracy: 0.7300\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 23s 145ms/step - loss: 11.1075 - accuracy: 0.8125 - val_loss: 19.1085 - val_accuracy: 0.8350\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 23s 145ms/step - loss: 9.5037 - accuracy: 0.8329 - val_loss: 26.3075 - val_accuracy: 0.8333\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 24s 152ms/step - loss: 8.5383 - accuracy: 0.8379 - val_loss: 18.4827 - val_accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=step, epochs=10,\n",
    "                              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 28)\n",
      "18.48273013649225\n"
     ]
    }
   ],
   "source": [
    "def compute_metric(pred, test):\n",
    "    res = 0.0\n",
    "    hei = pred.shape[0]\n",
    "    print(pred.shape)\n",
    "    for i in range(hei):\n",
    "        diff = (pred[i] - test[i])\n",
    "#         diff[::2] /= n_cols\n",
    "#         diff[1::2] /= n_rows\n",
    "#         diff *= 100\n",
    "#         print((diff ** 2).mean())\n",
    "        res += (diff ** 2).mean()\n",
    "    return res / hei\n",
    "\n",
    "print(compute_metric(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 42 10 49 16 47 51 35 39 36 27 35 15 36 20 32 32 33 45 31  1  0 28 24\n",
      "  0 28 24 26]\n",
      "[0 1 0 0 0 0 2 0 0 0 0 1 0 2 5 2 4 1 5 1 1 2 1 2 1 6 0 3]\n",
      "[0 1 0 2 2 1 5 0 2 0 2 1 1 0 0 2 2 1 3 0 1 3 4 0 0 0 0 2]\n",
      "[2 0 1 3 2 1 7 7 2 0 4 0 5 0 5 2 7 2 7 2 1 2 1 2 0 3 1 0]\n",
      "[1 1 2 2 0 1 3 5 3 0 2 0 0 2 5 1 1 1 0 2 1 1 3 0 0 0 0 1]\n",
      "[1 0 0 2 0 0 1 0 2 0 1 0 5 0 1 1 2 3 2 2 2 4 3 1 2 4 2 2]\n",
      "[1 2 1 0 3 2 4 3 2 0 2 2 1 2 0 1 0 0 2 0 0 0 0 0 0 3 1 1]\n",
      "[5 3 2 4 2 5 3 3 7 0 6 2 3 2 1 1 0 0 1 1 2 3 0 7 1 2 1 2]\n",
      "[2 3 3 2 3 1 0 0 0 0 1 0 1 3 2 2 1 1 0 0 0 3 0 1 1 1 3 0]\n",
      "[1 2 2 0 3 1 2 2 0 1 4 2 0 0 1 0 0 2 1 0 1 2 1 0 1 2 4 3]\n",
      "[2 0 0 1 2 0 1 5 2 1 4 0 2 4 0 5 1 1 0 3 3 2 2 2 2 4 0 5]\n",
      "[2 0 2 3 3 2 2 0 1 1 1 1 1 2 0 1 0 2 0 1 0 6 3 1 0 0 0 1]\n",
      "[3 3 5 0 5 0 4 2 0 1 0 2 2 1 3 3 0 2 0 1 3 2 2 0 0 1 1 2]\n",
      "[ 5  3  6  6 10  0 16  2  7  4 10  5  7  4 11  0 17  1 17  0  0  5  1  3\n",
      "  0  3  1  9]\n",
      "[ 9 14  8  9  8  2 15 10  1 12  3 11  8  7 10  2 12  4  9 11  1  2  0  0\n",
      "  5  4  2 14]\n",
      "[2 1 3 1 1 1 0 4 2 0 2 1 0 0 0 1 1 0 2 0 1 4 0 4 1 0 1 3]\n",
      "[1 3 1 1 2 0 1 3 1 1 2 0 3 1 5 2 5 1 0 1 3 4 3 0 4 1 0 1]\n",
      "[2 6 1 3 2 1 0 1 1 4 2 1 0 1 1 0 1 0 1 1 1 2 3 4 2 1 4 0]\n",
      "[0 2 3 0 4 1 1 2 1 4 3 0 3 6 0 3 0 1 0 1 0 2 3 2 3 4 3 2]\n",
      "[ 1  1  1  3  1  5  6  1  0  2  1  1  1  0  6  0  5  2  4  4  3  5  2  8\n",
      "  0  9  4 11]\n",
      "[6 0 4 1 1 1 0 1 6 0 1 0 2 1 2 2 0 2 0 2 4 4 5 0 3 1 2 1]\n",
      "[3 1 6 4 3 2 2 0 7 3 5 1 3 3 5 0 2 0 3 0 2 5 8 0 1 3 0 3]\n",
      "[0 1 0 3 0 0 3 0 1 0 2 0 1 2 2 0 3 0 4 4 1 3 2 1 3 0 3 5]\n",
      "[2 1 3 1 0 2 3 0 3 3 5 1 1 2 2 0 2 0 3 1 3 6 5 4 5 7 3 1]\n",
      "[ 1  0  6  0  5  3  5  2  3  2  6  1 10  1  1  0  4  3 10  6  2  0  1  2\n",
      "  2  2  1  0]\n",
      "[0 0 5 2 2 1 2 1 2 2 1 0 2 3 1 1 1 0 3 0 3 0 1 2 3 3 0 1]\n",
      "[2 1 3 1 0 2 2 1 1 0 0 2 1 0 1 1 0 1 0 0 0 2 0 0 1 1 5 3]\n",
      "[ 3 11  3  6  2  4  5  1  1  5  0  7  1  4  3  2  5  2  5  2  4  0  0  1\n",
      "  0  2  1  1]\n",
      "[2 3 7 1 2 3 3 4 2 1 3 0 1 3 1 4 0 2 7 1 0 2 1 2 1 2 1 2]\n",
      "[ 2 10  9  7 13  3 16  8  1 18  5 14  8 12 15  4 14  1 14  3 13  6  2  8\n",
      "  6  2  7  0]\n",
      "[1 0 1 3 2 0 0 4 1 1 2 0 0 1 0 0 0 0 0 1 0 4 1 4 2 3 2 4]\n",
      "[4 1 3 3 1 1 6 2 0 2 3 1 0 1 4 0 4 2 1 1 3 5 3 7 2 8 3 5]\n",
      "[2 1 2 0 3 3 1 1 4 1 4 0 2 0 0 0 1 0 2 0 4 4 4 2 0 3 0 3]\n",
      "[0 2 5 1 3 1 0 4 3 1 2 0 2 0 0 2 2 2 2 0 0 7 2 3 0 1 1 0]\n",
      "[0 0 5 1 7 0 6 1 1 1 1 1 4 1 4 4 6 3 7 0 4 3 1 0 0 0 1 3]\n",
      "[0 0 0 4 1 4 3 3 0 1 0 1 0 0 1 0 0 0 2 0 2 3 2 1 2 2 1 0]\n",
      "[ 5  3  3  1  1  0  1  3  0  0  1  0  1  1  0  1  1  2  3  0  0 10  1  1\n",
      "  0  0  0  2]\n",
      "[2 0 1 0 0 1 2 1 0 2 0 0 0 3 0 1 2 1 2 0 1 3 2 3 1 4 4 3]\n",
      "[8 0 3 3 2 0 0 2 5 0 5 0 3 2 1 1 0 0 2 0 7 0 0 9 0 2 1 4]\n",
      "[0 1 2 1 2 4 2 7 0 0 3 2 0 1 0 0 0 1 2 4 2 7 4 1 2 1 0 0]\n",
      "[3 4 1 0 4 0 1 3 0 0 1 0 2 1 2 0 3 1 3 3 3 3 3 2 1 4 0 5]\n",
      "[ 4  4  3  1  3  1  5  2  3  4  4  5  2  5  3  1  3  3  2  2  6  4  2  0\n",
      "  1 10  1  1]\n",
      "[0 0 0 3 2 2 5 4 3 0 4 2 0 0 0 0 2 1 0 0 1 1 0 0 0 3 2 3]\n",
      "[6 2 5 1 5 3 7 5 4 1 2 0 3 2 8 1 6 3 4 3 4 5 0 1 3 6 4 4]\n",
      "[3 1 1 2 4 2 3 0 2 0 1 4 0 0 2 0 0 1 2 0 4 2 3 3 2 1 3 0]\n",
      "[2 2 2 4 4 3 0 2 3 0 3 2 4 1 0 1 0 0 3 0 1 8 4 1 1 3 4 3]\n",
      "[1 2 1 3 5 1 9 0 0 2 2 0 3 0 2 1 6 0 6 1 0 0 1 0 2 1 4 1]\n",
      "[2 4 2 6 3 2 2 2 0 0 4 2 0 1 1 0 1 0 5 0 2 4 4 0 0 2 4 4]\n",
      "[2 1 3 0 1 0 3 2 4 1 2 1 2 4 0 3 1 1 0 1 0 7 1 2 0 5 2 4]\n",
      "[3 4 4 2 1 3 4 1 3 0 1 0 1 1 1 0 0 1 0 0 0 1 7 4 2 2 0 6]\n"
     ]
    }
   ],
   "source": [
    "for line in range(50):\n",
    "#     print(y_pred[line])\n",
    "#     print(y_test[line])\n",
    "    print((np.abs(y_pred[line] - y_test[line])).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
